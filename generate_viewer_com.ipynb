{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfcfb8cf-5410-495f-b6a7-a23e541fce97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, glob, json, time\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from chafs_roi.ccfs_time_reforecast import _Detrend, CombSerialLead, GenerateSeriesLeadPredTable\n",
    "from chafs_roi.ccfs_time_reforecast import Reforecast_by_FNID\n",
    "import multiprocessing as mp\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd549b4d-35f0-4041-9317-7514cc96460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindLatestDeakad(feature_sel):\n",
    "    return np.array([int(ft[-2:]) for ft in feature_sel]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147c14c1-36f6-4be5-88e3-0d12362d8a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FNID information ---------------------------- #\n",
    "fnids_info = pd.read_hdf('./data_in/fnids_info.hdf')\n",
    "fnids = fnids_info['fnid'].unique().tolist()\n",
    "country_code = fnids_info[['country','country_iso']].drop_duplicates().set_index('country').to_dict()['country_iso']\n",
    "country_to_use = country_code.keys()\n",
    "fnids_dict = fnids_info.groupby('country_iso')['fnid'].apply(lambda x: x.unique().tolist()).to_dict()\n",
    "# -------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4564f57-49be-4c97-b27e-0fdec9231fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Extract crop data ---------------------------- #\n",
    "# CPS (Country-Product-Season)\n",
    "cps = [\n",
    "    ['Somalia','Sorghum','Deyr'],\n",
    "    ['Somalia','Sorghum','Gu'],\n",
    "    ['Somalia','Maize','Deyr'],\n",
    "    ['Somalia','Maize','Gu'],\n",
    "    ['Malawi','Maize','Main'],\n",
    "    ['Kenya','Maize','Long'],\n",
    "    ['Kenya','Maize','Short'],\n",
    "    ['Burkina Faso','Maize','Main'],\n",
    "    # ['Burkina Faso','Sorghum','Main']\n",
    "]\n",
    "country_to_use = list(np.unique(np.array(cps)[:,0]))\n",
    "\n",
    "# Load FEWSNET admin boundaries\n",
    "shape = gpd.read_file('https://raw.githubusercontent.com/chc-ucsb/gscd/main/public/gscd_shape_stable.json').drop(columns='id')\n",
    "shape = shape[shape.ADMIN0.isin(country_to_use)].reset_index(drop=True)\n",
    "dist_info = shape[['FNID','ADMIN0','ADMIN1','ADMIN2']]\n",
    "dist_info.columns = ['fnid','country','admin1','admin2']\n",
    "column_order = ['fnid','country','admin1','admin2','year','product','season','month','dekad','day','out-of-sample','variable','value']\n",
    "\n",
    "# Load crop area, production, yield data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/chc-ucsb/gscd/main/public/gscd_data_stable.csv', index_col=0)\n",
    "# Reduce data according to CPS\n",
    "container = []\n",
    "for country_name, product_name, season_name in cps:\n",
    "    sub = df[\n",
    "            (df['country'] == country_name) &\n",
    "            (df['product'] == product_name) &\n",
    "            (df['season_name'] == season_name) &\n",
    "            (df['gscd_code'] == 'calibrated')\n",
    "    ]\n",
    "    container.append(sub)\n",
    "data = pd.concat(container, axis=0).reset_index(drop=True)\n",
    "data['year'] = data['harvest_year']\n",
    "data.rename(columns={'season_name':'season', 'indicator':'variable'}, inplace=True)\n",
    "data = data[['fnid','product','season','year','variable','value']]\n",
    "container0 = data.copy()\n",
    "container0.replace({'variable': {'area':'area_obs', \n",
    "                                 'production':'prod_obs',\n",
    "                                 'yield':'yield_obs'}},\n",
    "                   inplace=True)\n",
    "\n",
    "# (1) Long-term mean\n",
    "temp = data[data.year < 2019]\n",
    "long = temp.groupby(['fnid','product','season','variable'])['value'].mean().reset_index()\n",
    "long.replace({'variable':{'area':'area_mean_all',\n",
    "                          'production':'prod_mean_all',\n",
    "                          'yield':'yield_mean_all'\n",
    "                         }},\n",
    "             inplace=True\n",
    "            )\n",
    "\n",
    "\n",
    "# (2) Recent 10 years mean (2009-2018)\n",
    "temp = data[data.year.isin(np.arange(2009,2019))]\n",
    "last = temp.groupby(['fnid','product','season','variable'])['value'].mean().reset_index()\n",
    "last.replace({'variable':{'area':'area_mean_last10',\n",
    "                          'production':'prod_mean_last10',\n",
    "                          'yield':'yield_mean_last10'\n",
    "                         }},\n",
    "             inplace=True\n",
    "            )\n",
    "container1 = pd.concat([long,last],axis=0)\n",
    "container1.insert(3, 'year', np.nan)\n",
    "\n",
    "# Create a table for calculating % of errors to long and recent 10 years\n",
    "crop_mean_long = long.pivot_table(index=['fnid','product','season'], columns='variable',values='value')\n",
    "crop_mean_last10 = last.pivot_table(index=['fnid','product','season'], columns='variable',values='value')\n",
    "\n",
    "# Merge crop data\n",
    "container = pd.concat([container0, container1], axis=0)\n",
    "container[['month','dekad','day','out-of-sample']] = np.nan\n",
    "container = pd.merge(container, dist_info, left_on='fnid', right_on='fnid')\n",
    "container_obs = container[column_order]\n",
    "\n",
    "# Cropped area\n",
    "crop_area = pd.read_hdf('./data/cropmask/adm_cropland_area.hdf')['area00']*100\n",
    "crop_area = crop_area.reset_index()\n",
    "crop_area.columns = ['fnid', 'value']\n",
    "crop_area['variable'] = 'crop_area_percent'\n",
    "crop_area[['year','product','season','month','dekad','day','out-of-sample']] = np.nan\n",
    "crop_area = pd.merge(crop_area, dist_info, left_on='fnid', right_on='fnid')\n",
    "crop_area = crop_area[column_order]\n",
    "\n",
    "# Merge all\n",
    "container_crop = pd.concat([container_obs, crop_area], axis=0).reset_index(drop=True)\n",
    "# -------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92f39d8f-a57a-452b-9a69-4b3590492ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somalia-Sorghum-Deyr-ET\n",
      "Somalia-Sorghum-Gu-ET\n",
      "Somalia-Maize-Deyr-ET\n",
      "Somalia-Maize-Gu-ET\n",
      "Malawi-Maize-Main-ET\n",
      "Kenya-Maize-Long-ET\n",
      "Kenya-Maize-Short-ET\n",
      "Burkina Faso-Maize-Main-ET\n"
     ]
    }
   ],
   "source": [
    "# (3) Export reforecast results -------------------- #\n",
    "# Base dekads for temporal referencing\n",
    "dekad0 = pd.date_range('1980-01-01', '2023-12-31')\n",
    "d = dekad0.day - np.clip((dekad0.day-1) // 10, 0, 2)*10 - 1\n",
    "dekad0 = dekad0 - np.array(d, dtype=\"timedelta64[D]\")\n",
    "dekad0 = dekad0.unique()\n",
    "def dekad_date(dekad, lead):\n",
    "    return dekad0[dekad0.get_loc(dekad) - lead]\n",
    "\n",
    "# Extract forecast results\n",
    "def prettytable(df, fnid, product_name, season_name):\n",
    "    df.columns = ['harvest', 'lead', 'value']\n",
    "    df['date'] = np.vectorize(dekad_date)(df['harvest'],df['lead'])\n",
    "    df[['fnid','product','season']] = fnid, product_name, season_name\n",
    "    dt = df['date'].dt\n",
    "    df[['year', 'month', 'dekad', 'day']] = pd.concat([dt.year, dt.month, \n",
    "                                                       np.ceil(dt.day/10).astype(int), \n",
    "                                                       dt.day], axis=1).values\n",
    "    return df\n",
    "\n",
    "\n",
    "# Stacking forecast results\n",
    "list_model = ['ET']\n",
    "cps = [\n",
    "    ['Somalia','Sorghum','Deyr'],\n",
    "    ['Somalia','Sorghum','Gu'],\n",
    "    ['Somalia','Maize','Deyr'],\n",
    "    ['Somalia','Maize','Gu'],\n",
    "    ['Malawi','Maize','Main'],\n",
    "    ['Kenya','Maize','Long'],\n",
    "    ['Kenya','Maize','Short'],\n",
    "    ['Burkina Faso','Maize','Main'],\n",
    "    # ['Burkina Faso','Sorghum','Main']\n",
    "]\n",
    "container_out = []\n",
    "comb = product(cps, list_model)\n",
    "stime = time.time()\n",
    "for (country_name, product_name, season_name), model_name in comb:\n",
    "    exp_name = 'YFT_INDV_ALL'\n",
    "    country_iso = country_code[country_name]\n",
    "    print('%s-%s-%s-%s' % (country_name, product_name, season_name, model_name))\n",
    "\n",
    "    # Load forecat results\n",
    "    fn_format = './result/ccfs_reforecast_{:s}_{:s}_{:s}_{:s}_{:s}.npz'\n",
    "    box = np.load(fn_format.format(country_iso, product_name, season_name, model_name, exp_name), \n",
    "                  allow_pickle=True)['obox'].tolist()\n",
    "    box_fnids = box['box_fnids']\n",
    "    box_y_dt = box['box_y_dt']\n",
    "    box_hcst = box['box_hcst']\n",
    "    box_hcst_error = box['box_hcst_error']\n",
    "    box_hcst_low = box['box_hcst_low']\n",
    "    box_hcst_high = box['box_hcst_high']\n",
    "    box_fcst = box['box_fcst']\n",
    "    box_fcst_error = box['box_fcst_error']\n",
    "    box_fcst_low = box['box_fcst_low']\n",
    "    box_fcst_high = box['box_fcst_high']\n",
    "    box_rcst = box['box_rcst']\n",
    "    box_rcst_dt = box['box_rcst_dt']\n",
    "    box_rcst_low = box['box_rcst_low']\n",
    "    box_rcst_high = box['box_rcst_high']\n",
    "    box_nse_hcst = box['box_nse_hcst']\n",
    "    box_nse_fcst = box['box_nse_fcst']\n",
    "    box_mape_hcst = box['box_mape_hcst']\n",
    "    box_mape_fcst = box['box_mape_fcst']\n",
    "\n",
    "    # Loop per FNID\n",
    "    container = []\n",
    "    for fnid in box_fnids:\n",
    "        yield_long = crop_mean_long.loc[pd.IndexSlice[fnid,product_name,season_name],'yield_mean_all']\n",
    "        yield_last10 = crop_mean_last10.loc[pd.IndexSlice[fnid,product_name,season_name],'yield_mean_last10']\n",
    "\n",
    "        # (1) Hindcast + Forecast (values and percentages of last 10-year mean)\n",
    "        # - Hindcast\n",
    "        df_hcst = box_hcst[fnid].stack().reset_index()\n",
    "        df_hcst = prettytable(df_hcst, fnid, product_name, season_name)\n",
    "        df_hcst['out-of-sample'] = 0\n",
    "        df_hcst['variable'] = 'yield_fcst'\n",
    "        # - Forecast\n",
    "        df_fcst = box_fcst[fnid].stack().reset_index()\n",
    "        df_fcst = prettytable(df_fcst, fnid, product_name, season_name)\n",
    "        df_fcst['out-of-sample'] = 1\n",
    "        df_fcst['variable'] = 'yield_fcst'\n",
    "        # - Reconstruct\n",
    "        df_rcst = box_rcst[fnid].stack().reset_index()\n",
    "        df_rcst = prettytable(df_rcst, fnid, product_name, season_name)\n",
    "        df_rcst['out-of-sample'] = 2\n",
    "        df_rcst['variable'] = 'yield_fcst'\n",
    "        # - Merge them and remove the hindcast in the forecast period\n",
    "        df = pd.concat([df_rcst, df_hcst, df_fcst], axis=0).reset_index(drop=True)\n",
    "        # df = df.drop_duplicates(df.columns[[0,1,3,4,5,6,7,8,9,11]], keep='last').reset_index(drop=True)\n",
    "        container.append(df.copy())\n",
    "        # - Percentage to long-term mean \n",
    "        df_prct_long = df.copy()\n",
    "        df_prct_long['value'] = df_prct_long['value']/yield_long*100\n",
    "        df_prct_long['variable'] = 'yield_fcst_p30'\n",
    "        container.append(df_prct_long)\n",
    "        # - Percentage to last 10-year mean\n",
    "        df_prct_last10 = df.copy()\n",
    "        df_prct_last10['value'] = df_prct_last10['value']/yield_last10*100\n",
    "        df_prct_last10['variable'] = 'yield_fcst_p10'\n",
    "        container.append(df_prct_last10)\n",
    "        # - Percentage to last 10-year mean (detrended)\n",
    "        yield_dt = box_y_dt[fnid]\n",
    "        yield_last10_dt = yield_dt[yield_dt.index.year.isin(np.arange(2009, 2019))].mean()\n",
    "        df_rcst_dt = box_rcst_dt[fnid].stack().reset_index()\n",
    "        df_prct_last10_dt = prettytable(df_rcst_dt, fnid, product_name, season_name)\n",
    "        df_prct_last10_dt['out-of-sample'] = 2\n",
    "        df_prct_last10_dt['value'] = df_prct_last10_dt['value']/yield_last10_dt*100\n",
    "        df_prct_last10_dt['variable'] = 'yield_fcst_p10_dt'\n",
    "        container.append(df_prct_last10_dt)\n",
    "\n",
    "        # (2) Hindcast Low (values and percentages of last 10-year mean)\n",
    "        # - Hindcast\n",
    "        df_hcst = box_hcst_low[fnid].stack().reset_index()\n",
    "        df_hcst = prettytable(df_hcst, fnid, product_name, season_name)\n",
    "        df_hcst['out-of-sample'] = 0\n",
    "        df_hcst['variable'] = 'yield_fcst_low'\n",
    "        # - Forecast\n",
    "        df_fcst = box_fcst_low[fnid].stack().reset_index()\n",
    "        df_fcst = prettytable(df_fcst, fnid, product_name, season_name)\n",
    "        df_fcst['out-of-sample'] = 1\n",
    "        df_fcst['variable'] = 'yield_fcst_low'\n",
    "        # - Reconstruct\n",
    "        df_rcst = box_rcst_low[fnid].stack().reset_index()\n",
    "        df_rcst = prettytable(df_rcst, fnid, product_name, season_name)\n",
    "        df_rcst['out-of-sample'] = 2\n",
    "        df_rcst['variable'] = 'yield_fcst_low'\n",
    "        # - Merge them and remove the hindcast in the forecast period\n",
    "        df = pd.concat([df_rcst, df_hcst, df_fcst], axis=0).reset_index(drop=True)\n",
    "        # df = df.drop_duplicates(df.columns[[0,1,3,4,5,6,7,8,9,11]], keep='last').reset_index(drop=True)\n",
    "        container.append(df.copy())\n",
    "        # - Percentage to long-term mean \n",
    "        df_prct_long = df.copy()\n",
    "        df_prct_long['value'] = df_prct_long['value']/yield_long*100\n",
    "        df_prct_long['variable'] = 'yield_fcst_low_p30'\n",
    "        container.append(df_prct_long)\n",
    "        # - Percentage to last 10-year mean\n",
    "        df_prct_last10 = df.copy()\n",
    "        df_prct_last10['value'] = df_prct_last10['value']/yield_last10*100\n",
    "        df_prct_last10['variable'] = 'yield_fcst_low_p10'\n",
    "        container.append(df_prct_last10)\n",
    "\n",
    "        # (2) Hindcast High (values and percentages of last 10-year mean)\n",
    "        # - Hindcast\n",
    "        df_hcst = box_hcst_high[fnid].stack().reset_index()\n",
    "        df_hcst = prettytable(df_hcst, fnid, product_name, season_name)\n",
    "        df_hcst['out-of-sample'] = 0\n",
    "        df_hcst['variable'] = 'yield_fcst_high'\n",
    "        # - Forecast\n",
    "        df_fcst = box_fcst_high[fnid].stack().reset_index()\n",
    "        df_fcst = prettytable(df_fcst, fnid, product_name, season_name)\n",
    "        df_fcst['out-of-sample'] = 1\n",
    "        df_fcst['variable'] = 'yield_fcst_high'\n",
    "        # - Reconstruct\n",
    "        df_rcst = box_rcst_high[fnid].stack().reset_index()\n",
    "        df_rcst = prettytable(df_rcst, fnid, product_name, season_name)\n",
    "        df_rcst['out-of-sample'] = 2\n",
    "        df_rcst['variable'] = 'yield_fcst_high'\n",
    "        # - Merge them and remove the hindcast in the forecast period\n",
    "        df = pd.concat([df_rcst, df_hcst, df_fcst], axis=0).reset_index(drop=True)\n",
    "        # df = df.drop_duplicates(df.columns[[0,1,3,4,5,6,7,8,9,11]], keep='last').reset_index(drop=True)\n",
    "        container.append(df.copy())\n",
    "        # - Percentage to long-term mean \n",
    "        df_prct_long = df.copy()\n",
    "        df_prct_long['value'] = df_prct_long['value']/yield_long*100\n",
    "        df_prct_long['variable'] = 'yield_fcst_high_p30'\n",
    "        container.append(df_prct_long)\n",
    "        # - Percentage to last 10-year mean\n",
    "        df_prct_last10 = df.copy()\n",
    "        df_prct_last10['value'] = df_prct_last10['value']/yield_last10*100\n",
    "        df_prct_last10['variable'] = 'yield_fcst_high_p10'\n",
    "        container.append(df_prct_last10)\n",
    "\n",
    "        # (4) Hindcast error\n",
    "        # - Hindcast\n",
    "        df_hcst = box_hcst_error[fnid].stack().reset_index()\n",
    "        df_hcst = prettytable(df_hcst, fnid, product_name, season_name)\n",
    "        df_hcst['out-of-sample'] = 0\n",
    "        df_hcst['variable'] = 'yield_fcst_error'\n",
    "        # - Forecast\n",
    "        df_fcst = box_fcst_error[fnid].stack().reset_index()\n",
    "        df_fcst = prettytable(df_fcst, fnid, product_name, season_name)\n",
    "        df_fcst['out-of-sample'] = 1\n",
    "        df_fcst['variable'] = 'yield_fcst_error'\n",
    "        # - Merge them and remove the hindcast in the forecast period\n",
    "        df = pd.concat([df_hcst, df_fcst], axis=0).reset_index(drop=True)\n",
    "        # df = df.drop_duplicates(df.columns[[0,1,3,4,5,6,7,8,9,11]], keep='last').reset_index(drop=True)\n",
    "        container.append(df.copy())\n",
    "    container = pd.concat(container, axis=0)\n",
    "    container = pd.merge(container, dist_info, left_on='fnid', right_on='fnid')\n",
    "    container_hcst = container[[*column_order, 'lead']]\n",
    "\n",
    "    # NSE Hindcast\n",
    "    temp = box_nse_hcst\n",
    "    temp = temp.stack().reset_index()\n",
    "    temp.columns = ['fnid','lead','value']\n",
    "    temp['variable'] = 'yield_nse'\n",
    "    base = container_hcst[['fnid','country','admin1','admin2','product','season','month','dekad','day','lead']].drop_duplicates()\n",
    "    container_nse_hcst = pd.merge(temp, base, left_on=['fnid','lead'], right_on=['fnid','lead'], how='outer')\n",
    "    container_nse_hcst['out-of-sample'] = 0\n",
    "    # NSE Forecast\n",
    "    temp = box_nse_fcst\n",
    "    temp = temp.stack().reset_index()\n",
    "    temp.columns = ['fnid','lead','value']\n",
    "    temp['variable'] = 'yield_nse'\n",
    "    base = container_hcst[['fnid','country','admin1','admin2','product','season','month','dekad','day','lead']].drop_duplicates()\n",
    "    container_nse_fcst = pd.merge(temp, base, left_on=['fnid','lead'], right_on=['fnid','lead'], how='outer')\n",
    "    container_nse_fcst['out-of-sample'] = 1\n",
    "\n",
    "    # MAPE Hindcast\n",
    "    temp = box_mape_hcst*100\n",
    "    temp = temp.stack().reset_index()\n",
    "    temp.columns = ['fnid','lead','value']\n",
    "    temp['variable'] = 'yield_mape'\n",
    "    base = container_hcst[['fnid','country','admin1','admin2','product','season','month','dekad','day','lead']].drop_duplicates()\n",
    "    container_mape_hcst = pd.merge(temp, base, left_on=['fnid','lead'], right_on=['fnid','lead'], how='outer')\n",
    "    container_mape_hcst['out-of-sample'] = 0\n",
    "    # MAPE Forecast\n",
    "    temp = box_mape_fcst*100\n",
    "    temp = temp.stack().reset_index()\n",
    "    temp.columns = ['fnid','lead','value']\n",
    "    temp['variable'] = 'yield_mape'\n",
    "    base = container_hcst[['fnid','country','admin1','admin2','product','season','month','dekad','day','lead']].drop_duplicates()\n",
    "    container_mape_fcst = pd.merge(temp, base, left_on=['fnid','lead'], right_on=['fnid','lead'], how='outer')\n",
    "    container_mape_fcst['out-of-sample'] = 1\n",
    "\n",
    "    # Merge forecast results and MAPE\n",
    "    container_forecast = pd.concat([\n",
    "        container_hcst, \n",
    "        container_nse_hcst, container_nse_fcst,\n",
    "        container_mape_hcst, container_mape_fcst,\n",
    "    ], axis=0)[column_order].reset_index(drop=True)\n",
    "\n",
    "    # # Exclude districts modeled with insufficient records\n",
    "    # min_records = 15\n",
    "    # sub_info = fnids_info[\n",
    "    #     (fnids_info['country'] == country_name) &\n",
    "    #     (fnids_info['product'] == product_name) &\n",
    "    #     (fnids_info['season_name'] == season_name)\n",
    "    # ]\n",
    "    # fnids_valid = sub_info.loc[sub_info['record'] >= min_records, 'fnid'].values.tolist()\n",
    "    # container_forecast = container_forecast[container_forecast['fnid'].isin(fnids_valid)]\n",
    "    container_forecast['model'] = model_name\n",
    "    container_out.append(container_forecast)\n",
    "container_forecast = pd.concat(container_out, axis=0).reset_index(drop=True)\n",
    "# -------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47d899d0-ba11-49a5-8712-3314eda7cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Season start month and Forecast start month ------ #\n",
    "# Start months of crop season and forecast\n",
    "cols = ['country','product','season','forecast_start_month','season_start_month']\n",
    "start = [\n",
    "    ['Somalia','Sorghum','Gu',2,3],\n",
    "    ['Somalia','Sorghum','Deyr',9,10],\n",
    "    ['Somalia','Maize','Gu',2,3],\n",
    "    ['Somalia','Maize','Deyr',9,10],\n",
    "    ['Malawi','Maize','Main',10,11],\n",
    "    ['Kenya','Maize','Long',2,3],\n",
    "    ['Kenya','Maize','Short',9,10],\n",
    "    ['Burkina Faso','Maize','Main',4,5],\n",
    "]\n",
    "start = pd.DataFrame(start, columns=cols)\n",
    "# -------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a86380f-333d-49ee-9d37-403cbd186586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./viewer/viewer_data_com.csv is saved.\n",
      "        country  product season     latest\n",
      "0       Somalia  Sorghum   Deyr 2022-12-21\n",
      "1       Somalia  Sorghum     Gu 2022-07-21\n",
      "2       Somalia    Maize   Deyr 2022-12-21\n",
      "3       Somalia    Maize     Gu 2022-07-21\n",
      "4        Malawi    Maize   Main 2022-12-21\n",
      "5         Kenya    Maize   Long 2022-07-21\n",
      "6         Kenya    Maize  Short 2022-12-21\n",
      "7  Burkina Faso    Maize   Main 2022-09-21\n"
     ]
    }
   ],
   "source": [
    "# Save the \"viewer_com.csv\" ------------------------ #\n",
    "# Export data\n",
    "# container = pd.concat([container_crop, container_forecast], axis=0).reset_index(drop=True)\n",
    "container = pd.concat([container_forecast], axis=0).reset_index(drop=True)\n",
    "container = container.merge(start, on=['country','product','season'], how='outer') # 'outer' for 'crop_area_percent'\n",
    "container = container[['fnid','country','admin1','admin2','year','product','season',\n",
    "                       'forecast_start_month','season_start_month',\n",
    "                       'month','dekad','day','model','out-of-sample','variable','value']]\n",
    "container = container[container['variable'].notna()]\n",
    "fn_out = './viewer/viewer_data_com.csv'\n",
    "container.to_csv(fn_out)\n",
    "print('%s is saved.' % fn_out)\n",
    "\n",
    "# # Export shapefile\n",
    "# fn_out = './viewer/viewer_data.shp'\n",
    "# shape.to_file(fn_out)\n",
    "# print('%s is saved.' % fn_out)\n",
    "\n",
    "df = pd.read_csv('./viewer/viewer_data_com.csv', low_memory=False).drop(['Unnamed: 0'],axis=1)\n",
    "df['date'] = pd.to_datetime(df[['year','month','day']])\n",
    "cps = df.loc[df['season'].notna(),['country','product','season']].drop_duplicates().reset_index(drop=True)\n",
    "for i, (country_name, product_name, season_name) in cps.iterrows():\n",
    "    sub = df[\n",
    "        (df['country'] == country_name) &\n",
    "        (df['product'] == product_name) &\n",
    "        (df['season'] == season_name) &\n",
    "        (df['year'].isin([2022,2023])) &\n",
    "        (df['out-of-sample'] == 2) &\n",
    "        (df['variable'] == 'yield_fcst')\n",
    "    ]\n",
    "    # print(sub.groupby(['country','fnid','product','season'])['date'].max())\n",
    "    cps.loc[i,'latest'] = sub['date'].max()\n",
    "print(cps)\n",
    "# print(df['variable'].unique())\n",
    "# df[['out-of-sample','variable']].drop_duplicates()\n",
    "# -------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccbbbb5-40cd-44d1-a300-df2f7624dd76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c135e284-b311-41de-a30d-42009bbdeda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb91b7cb-01d4-4d23-8b7f-bee4bdee384d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba515cc6-7dce-4370-9c25-e6036bbeab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def generate_viewer_com():\n",
    "    \n",
    "    # Load FNID information ---------------------------- #\n",
    "    fnids_info = pd.read_hdf('./data_in/fnids_info.hdf')\n",
    "    fnids = fnids_info['fnid'].unique().tolist()\n",
    "    country_code = fnids_info[['country','country_iso']].drop_duplicates().set_index('country').to_dict()['country_iso']\n",
    "    country_to_use = country_code.keys()\n",
    "    fnids_dict = fnids_info.groupby('country_iso')['fnid'].apply(lambda x: x.unique().tolist()).to_dict()\n",
    "    # -------------------------------------------------- #\n",
    "    \n",
    "#     # (1) Reforecast all years ------------------------- #\n",
    "#     # In order to run multiprocessing codes on Ipython, we need to make a function of main work\n",
    "#     # (Source: https://medium.com/@grvsinghal/speed-up-your-python-code-using-multiprocessing-on-windows-and-jupyter-or-ipython-2714b49d6fac)\n",
    "#     list_model = ['ET']\n",
    "#     cps = [\n",
    "#         ['Somalia','Sorghum','Deyr'],\n",
    "#         ['Somalia','Sorghum','Gu'],\n",
    "#         ['Somalia','Maize','Deyr'],\n",
    "#         ['Somalia','Maize','Gu'],\n",
    "#         ['Malawi','Maize','Main'],\n",
    "#         ['Kenya','Maize','Long'],\n",
    "#         ['Kenya','Maize','Short'],\n",
    "#         ['Burkina Faso','Maize','Main'],\n",
    "#         # ['Burkina Faso','Sorghum','Main']\n",
    "#     ]\n",
    "#     comb = product(cps, list_model)\n",
    "#     stime = time.time()\n",
    "#     for (country_name, product_name, season_name), model_name in comb:\n",
    "#         country_iso = country_code[country_name]\n",
    "#         leadmat = [18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1]\n",
    "#         print('%s-%s-%s-%s' % (country_name, product_name, season_name, model_name))\n",
    "\n",
    "#         # Basic parameters\n",
    "#         indicator_name = 'yield'\n",
    "#         lead_dkd = 'all'\n",
    "#         flag_dekad = True\n",
    "#         flag_ext = True\n",
    "#         flag_serial = True\n",
    "#         isPower = False\n",
    "#         isTrend = True\n",
    "#         exp_name = 'YFT_INDV_ALL'\n",
    "#         note = ''\n",
    "\n",
    "#         # Remove the missing FNIDS\n",
    "#         fn_format = './data_out/ccfs/ccfs_{:s}_{:s}_{:s}_{:s}_{:s}.npz'\n",
    "#         fnids_exists = [fnid for fnid in fnids_dict[country_iso] if \n",
    "#                         os.path.exists(fn_format.format(fnid, product_name, season_name, model_name, exp_name))]\n",
    "\n",
    "#         # Initial parameters\n",
    "#         obox = dict()\n",
    "#         box_y = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_y_dt = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_ssorder = pd.DataFrame(index=fnids_exists, columns=leadmat, dtype=np.float32).rename_axis(index='fnid', columns=\"lead\")\n",
    "#         box_nse_hcst = box_ssorder.copy()\n",
    "#         box_nse_fcst = box_ssorder.copy()\n",
    "#         box_mape_hcst = box_ssorder.copy()\n",
    "#         box_mape_fcst = box_ssorder.copy()\n",
    "#         box_hcst = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_hcst_error = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_hcst_low = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_hcst_high = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_fcst = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_fcst_error = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_fcst_low = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_fcst_high = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_rcst = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_rcst_dt = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_rcst_low = {fnid: [] for fnid in fnids_exists}\n",
    "#         box_rcst_high = {fnid: [] for fnid in fnids_exists}\n",
    "\n",
    "#         # Multiprocessing per district\n",
    "#         pool = mp.Pool(4)\n",
    "#         jobs = []\n",
    "#         for fnid in fnids_exists:\n",
    "#             bp = (\n",
    "#                 fnid, product_name, season_name, indicator_name, \n",
    "#                 model_name, lead_dkd, flag_dekad, flag_ext, flag_serial, \n",
    "#                 isPower, isTrend, exp_name, note\n",
    "#             )\n",
    "#             jobs.append(pool.apply_async(Reforecast_by_FNID, bp))\n",
    "#         pool.close()\n",
    "#         pool.join()\n",
    "#         output = [job.get() for job in jobs]\n",
    "\n",
    "#         # Store predicted values, errors, confidence intervals\n",
    "#         for ibox in output:\n",
    "#             fnid = ibox['fnid']\n",
    "#             box_y[fnid] = ibox['y']\n",
    "#             box_y_dt[fnid] = ibox['y_dt']\n",
    "#             box_ssorder.loc[fnid,:] = ibox['ssorder']\n",
    "#             box_nse_hcst.loc[fnid,:] = ibox['score'].loc['nse_hcst']\n",
    "#             box_nse_fcst.loc[fnid,:] = ibox['score'].loc['nse_fcst']\n",
    "#             box_mape_hcst.loc[fnid,:] = ibox['score'].loc['mape_hcst']\n",
    "#             box_mape_fcst.loc[fnid,:] = ibox['score'].loc['mape_fcst']\n",
    "#             box_hcst[fnid] = ibox['hcst']\n",
    "#             box_hcst_error[fnid] = ibox['hcst_error']\n",
    "#             box_hcst_low[fnid] = ibox['hcst_low']\n",
    "#             box_hcst_high[fnid] = ibox['hcst_high']\n",
    "#             box_fcst[fnid] = ibox['fcst']\n",
    "#             box_fcst_error[fnid] = ibox['fcst_error']\n",
    "#             box_fcst_low[fnid] = ibox['fcst_low']\n",
    "#             box_fcst_high[fnid] = ibox['fcst_high']\n",
    "#             box_rcst[fnid] = ibox['rcst']\n",
    "#             box_rcst_dt[fnid] = ibox['rcst_dt']\n",
    "#             box_rcst_low[fnid] = ibox['rcst_low']\n",
    "#             box_rcst_high[fnid] = ibox['rcst_high']\n",
    "\n",
    "#         # Save values\n",
    "#         obox['box_fnids'] = fnids_exists\n",
    "#         obox['box_y'] = box_y\n",
    "#         obox['box_y_dt'] = box_y_dt\n",
    "#         obox['box_ssorder'] = box_ssorder\n",
    "#         obox['box_nse_hcst'] = box_nse_hcst\n",
    "#         obox['box_nse_fcst'] = box_nse_fcst\n",
    "#         obox['box_mape_hcst'] = box_mape_hcst\n",
    "#         obox['box_mape_fcst'] = box_mape_fcst\n",
    "#         obox['box_hcst'] = box_hcst\n",
    "#         obox['box_hcst_error'] = box_hcst_error\n",
    "#         obox['box_hcst_low'] = box_hcst_low\n",
    "#         obox['box_hcst_high'] = box_hcst_high\n",
    "#         obox['box_fcst'] = box_fcst\n",
    "#         obox['box_fcst_error'] = box_fcst_error\n",
    "#         obox['box_fcst_low'] = box_fcst_low\n",
    "#         obox['box_fcst_high'] = box_fcst_high\n",
    "#         obox['box_rcst'] = box_rcst\n",
    "#         obox['box_rcst_dt'] = box_rcst_dt\n",
    "#         obox['box_rcst_low'] = box_rcst_low\n",
    "#         obox['box_rcst_high'] = box_rcst_high\n",
    "#         fn_out = './result/ccfs_reforecast_%s_%s_%s_%s_%s.npz' % (country_iso, product_name, season_name, model_name, exp_name)\n",
    "#         np.savez_compressed(fn_out, obox=obox)\n",
    "#         print('%s is saved.' % fn_out)\n",
    "#     print('%.1fs took' % (time.time() - stime))\n",
    "#     # -------------------------------------------------- #\n",
    "    \n",
    "    \n",
    "    # (2) Extract crop data ---------------------------- #\n",
    "    # CPS (Country-Product-Season)\n",
    "    cps = [\n",
    "        ['Somalia','Sorghum','Deyr'],\n",
    "        ['Somalia','Sorghum','Gu'],\n",
    "        ['Somalia','Maize','Deyr'],\n",
    "        ['Somalia','Maize','Gu'],\n",
    "        ['Malawi','Maize','Main'],\n",
    "        ['Kenya','Maize','Long'],\n",
    "        ['Kenya','Maize','Short'],\n",
    "        ['Burkina Faso','Maize','Main'],\n",
    "        # ['Burkina Faso','Sorghum','Main']\n",
    "    ]\n",
    "    country_to_use = list(np.unique(np.array(cps)[:,0]))\n",
    "\n",
    "    # Load FEWSNET admin boundaries\n",
    "    shape = gpd.read_file('https://raw.githubusercontent.com/chc-ucsb/gscd/main/public/gscd_shape_stable.json').drop(columns='id')\n",
    "    shape = shape[shape.ADMIN0.isin(country_to_use)].reset_index(drop=True)\n",
    "    dist_info = shape[['FNID','ADMIN0','ADMIN1','ADMIN2']]\n",
    "    dist_info.columns = ['fnid','country','admin1','admin2']\n",
    "    column_order = ['fnid','country','admin1','admin2','year','product','season','month','dekad','day','out-of-sample','variable','value']\n",
    "\n",
    "    # Load crop area, production, yield data\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/chc-ucsb/gscd/main/public/gscd_data_stable.csv', index_col=0)\n",
    "    # Reduce data according to CPS\n",
    "    container = []\n",
    "    for country_name, product_name, season_name in cps:\n",
    "        sub = df[\n",
    "                (df['country'] == country_name) &\n",
    "                (df['product'] == product_name) &\n",
    "                (df['season_name'] == season_name) &\n",
    "                (df['gscd_code'] == 'calibrated')\n",
    "        ]\n",
    "        container.append(sub)\n",
    "    data = pd.concat(container, axis=0).reset_index(drop=True)\n",
    "    data['year'] = data['harvest_year']\n",
    "    data.rename(columns={'season_name':'season', 'indicator':'variable'}, inplace=True)\n",
    "    data = data[['fnid','product','season','year','variable','value']]\n",
    "    container0 = data.copy()\n",
    "    container0.replace({'variable': {'area':'area_obs', \n",
    "                                     'production':'prod_obs',\n",
    "                                     'yield':'yield_obs'}},\n",
    "                       inplace=True)\n",
    "\n",
    "    # (1) Long-term mean\n",
    "    temp = data[data.year < 2019]\n",
    "    long = temp.groupby(['fnid','product','season','variable'])['value'].mean().reset_index()\n",
    "    long.replace({'variable':{'area':'area_mean_all',\n",
    "                              'production':'prod_mean_all',\n",
    "                              'yield':'yield_mean_all'\n",
    "                             }},\n",
    "                 inplace=True\n",
    "                )\n",
    "\n",
    "\n",
    "    # (2) Recent 10 years mean (2009-2018)\n",
    "    temp = data[data.year.isin(np.arange(2009,2019))]\n",
    "    last = temp.groupby(['fnid','product','season','variable'])['value'].mean().reset_index()\n",
    "    last.replace({'variable':{'area':'area_mean_last10',\n",
    "                              'production':'prod_mean_last10',\n",
    "                              'yield':'yield_mean_last10'\n",
    "                             }},\n",
    "                 inplace=True\n",
    "                )\n",
    "    container1 = pd.concat([long,last],axis=0)\n",
    "    container1.insert(3, 'year', np.nan)\n",
    "\n",
    "    # Create a table for calculating % of errors to long and recent 10 years\n",
    "    crop_mean_long = long.pivot_table(index=['fnid','product','season'], columns='variable',values='value')\n",
    "    crop_mean_last10 = last.pivot_table(index=['fnid','product','season'], columns='variable',values='value')\n",
    "\n",
    "    # Merge crop data\n",
    "    container = pd.concat([container0, container1], axis=0)\n",
    "    container[['month','dekad','day','out-of-sample']] = np.nan\n",
    "    container = pd.merge(container, dist_info, left_on='fnid', right_on='fnid')\n",
    "    container_obs = container[column_order]\n",
    "\n",
    "    # Cropped area\n",
    "    crop_area = pd.read_hdf('./data/cropmask/adm_cropland_area.hdf')['area00']*100\n",
    "    crop_area = crop_area.reset_index()\n",
    "    crop_area.columns = ['fnid', 'value']\n",
    "    crop_area['variable'] = 'crop_area_percent'\n",
    "    crop_area[['year','product','season','month','dekad','day','out-of-sample']] = np.nan\n",
    "    crop_area = pd.merge(crop_area, dist_info, left_on='fnid', right_on='fnid')\n",
    "    crop_area = crop_area[column_order]\n",
    "\n",
    "    # Merge all\n",
    "    container_crop = pd.concat([container_obs, crop_area], axis=0).reset_index(drop=True)\n",
    "    # -------------------------------------------------- #\n",
    "    \n",
    "    \n",
    "    # (3) Export reforecast results -------------------- #\n",
    "    # Base dekads for temporal referencing\n",
    "    dekad0 = pd.date_range('1980-01-01', '2023-12-31')\n",
    "    d = dekad0.day - np.clip((dekad0.day-1) // 10, 0, 2)*10 - 1\n",
    "    dekad0 = dekad0 - np.array(d, dtype=\"timedelta64[D]\")\n",
    "    dekad0 = dekad0.unique()\n",
    "    def dekad_date(dekad, lead):\n",
    "        return dekad0[dekad0.get_loc(dekad) - lead]\n",
    "\n",
    "    # Extract forecast results\n",
    "    def prettytable(df, fnid, product_name, season_name):\n",
    "        df.columns = ['harvest', 'lead', 'value']\n",
    "        df['date'] = np.vectorize(dekad_date)(df['harvest'],df['lead'])\n",
    "        df[['fnid','product','season']] = fnid, product_name, season_name\n",
    "        dt = df['date'].dt\n",
    "        df[['year', 'month', 'dekad', 'day']] = pd.concat([dt.year, dt.month, \n",
    "                                                           np.ceil(dt.day/10).astype(int), \n",
    "                                                           dt.day], axis=1).values\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    # Stacking forecast results\n",
    "    list_model = ['ET']\n",
    "    cps = [\n",
    "        ['Somalia','Sorghum','Deyr'],\n",
    "        ['Somalia','Sorghum','Gu'],\n",
    "        ['Somalia','Maize','Deyr'],\n",
    "        ['Somalia','Maize','Gu'],\n",
    "        ['Malawi','Maize','Main'],\n",
    "        ['Kenya','Maize','Long'],\n",
    "        ['Kenya','Maize','Short'],\n",
    "        ['Burkina Faso','Maize','Main'],\n",
    "        # ['Burkina Faso','Sorghum','Main']\n",
    "    ]\n",
    "    container_out = []\n",
    "    comb = product(cps, list_model)\n",
    "    stime = time.time()\n",
    "    for (country_name, product_name, season_name), model_name in comb:\n",
    "        exp_name = 'YFT_INDV_ALL'\n",
    "        country_iso = country_code[country_name]\n",
    "        print('%s-%s-%s-%s' % (country_name, product_name, season_name, model_name))\n",
    "\n",
    "        # Load forecat results\n",
    "        fn_format = './result/ccfs_reforecast_{:s}_{:s}_{:s}_{:s}_{:s}.npz'\n",
    "        box = np.load(fn_format.format(country_iso, product_name, season_name, model_name, exp_name), \n",
    "                      allow_pickle=True)['obox'].tolist()\n",
    "        box_fnids = box['box_fnids']\n",
    "        box_y_dt = box['box_y_dt']\n",
    "        box_hcst = box['box_hcst']\n",
    "        box_hcst_error = box['box_hcst_error']\n",
    "        box_hcst_low = box['box_hcst_low']\n",
    "        box_hcst_high = box['box_hcst_high']\n",
    "        box_fcst = box['box_fcst']\n",
    "        box_fcst_error = box['box_fcst_error']\n",
    "        box_fcst_low = box['box_fcst_low']\n",
    "        box_fcst_high = box['box_fcst_high']\n",
    "        box_rcst = box['box_rcst']\n",
    "        box_rcst_dt = box['box_rcst_dt']\n",
    "        box_rcst_low = box['box_rcst_low']\n",
    "        box_rcst_high = box['box_rcst_high']\n",
    "        box_nse_hcst = box['box_nse_hcst']\n",
    "        box_nse_fcst = box['box_nse_fcst']\n",
    "        box_mape_hcst = box['box_mape_hcst']\n",
    "        box_mape_fcst = box['box_mape_fcst']\n",
    "\n",
    "        # Loop per FNID\n",
    "        container = []\n",
    "        for fnid in box_fnids:\n",
    "            yield_long = crop_mean_long.loc[pd.IndexSlice[fnid,product_name,season_name],'yield_mean_all']\n",
    "            yield_last10 = crop_mean_last10.loc[pd.IndexSlice[fnid,product_name,season_name],'yield_mean_last10']\n",
    "\n",
    "            # (1) Hindcast + Forecast (values and percentages of last 10-year mean)\n",
    "            # - Hindcast\n",
    "            df_hcst = box_hcst[fnid].stack().reset_index()\n",
    "            df_hcst = prettytable(df_hcst, fnid, product_name, season_name)\n",
    "            df_hcst['out-of-sample'] = 0\n",
    "            df_hcst['variable'] = 'yield_fcst'\n",
    "            # - Forecast\n",
    "            df_fcst = box_fcst[fnid].stack().reset_index()\n",
    "            df_fcst = prettytable(df_fcst, fnid, product_name, season_name)\n",
    "            df_fcst['out-of-sample'] = 1\n",
    "            df_fcst['variable'] = 'yield_fcst'\n",
    "            # - Reconstruct\n",
    "            df_rcst = box_rcst[fnid].stack().reset_index()\n",
    "            df_rcst = prettytable(df_rcst, fnid, product_name, season_name)\n",
    "            df_rcst['out-of-sample'] = 2\n",
    "            df_rcst['variable'] = 'yield_fcst'\n",
    "            # - Merge them and remove the hindcast in the forecast period\n",
    "            df = pd.concat([df_rcst, df_hcst, df_fcst], axis=0).reset_index(drop=True)\n",
    "            # df = df.drop_duplicates(df.columns[[0,1,3,4,5,6,7,8,9,11]], keep='last').reset_index(drop=True)\n",
    "            container.append(df.copy())\n",
    "            # - Percentage to long-term mean \n",
    "            df_prct_long = df.copy()\n",
    "            df_prct_long['value'] = df_prct_long['value']/yield_long*100\n",
    "            df_prct_long['variable'] = 'yield_fcst_p30'\n",
    "            container.append(df_prct_long)\n",
    "            # - Percentage to last 10-year mean\n",
    "            df_prct_last10 = df.copy()\n",
    "            df_prct_last10['value'] = df_prct_last10['value']/yield_last10*100\n",
    "            df_prct_last10['variable'] = 'yield_fcst_p10'\n",
    "            container.append(df_prct_last10)\n",
    "            # - Percentage to last 10-year mean (detrended)\n",
    "            yield_dt = box_y_dt[fnid]\n",
    "            yield_last10_dt = yield_dt[yield_dt.index.year.isin(np.arange(2009, 2019))].mean()\n",
    "            df_rcst_dt = box_rcst_dt[fnid].stack().reset_index()\n",
    "            df_prct_last10_dt = prettytable(df_rcst_dt, fnid, product_name, season_name)\n",
    "            df_prct_last10_dt['out-of-sample'] = 2\n",
    "            df_prct_last10_dt['value'] = df_prct_last10_dt['value']/yield_last10_dt*100\n",
    "            df_prct_last10_dt['variable'] = 'yield_fcst_p10_dt'\n",
    "            container.append(df_prct_last10_dt)\n",
    "\n",
    "            # (2) Hindcast Low (values and percentages of last 10-year mean)\n",
    "            # - Hindcast\n",
    "            df_hcst = box_hcst_low[fnid].stack().reset_index()\n",
    "            df_hcst = prettytable(df_hcst, fnid, product_name, season_name)\n",
    "            df_hcst['out-of-sample'] = 0\n",
    "            df_hcst['variable'] = 'yield_fcst_low'\n",
    "            # - Forecast\n",
    "            df_fcst = box_fcst_low[fnid].stack().reset_index()\n",
    "            df_fcst = prettytable(df_fcst, fnid, product_name, season_name)\n",
    "            df_fcst['out-of-sample'] = 1\n",
    "            df_fcst['variable'] = 'yield_fcst_low'\n",
    "            # - Reconstruct\n",
    "            df_rcst = box_rcst_low[fnid].stack().reset_index()\n",
    "            df_rcst = prettytable(df_rcst, fnid, product_name, season_name)\n",
    "            df_rcst['out-of-sample'] = 2\n",
    "            df_rcst['variable'] = 'yield_fcst_low'\n",
    "            # - Merge them and remove the hindcast in the forecast period\n",
    "            df = pd.concat([df_rcst, df_hcst, df_fcst], axis=0).reset_index(drop=True)\n",
    "            # df = df.drop_duplicates(df.columns[[0,1,3,4,5,6,7,8,9,11]], keep='last').reset_index(drop=True)\n",
    "            container.append(df.copy())\n",
    "            # - Percentage to long-term mean \n",
    "            df_prct_long = df.copy()\n",
    "            df_prct_long['value'] = df_prct_long['value']/yield_long*100\n",
    "            df_prct_long['variable'] = 'yield_fcst_low_p30'\n",
    "            container.append(df_prct_long)\n",
    "            # - Percentage to last 10-year mean\n",
    "            df_prct_last10 = df.copy()\n",
    "            df_prct_last10['value'] = df_prct_last10['value']/yield_last10*100\n",
    "            df_prct_last10['variable'] = 'yield_fcst_low_p10'\n",
    "            container.append(df_prct_last10)\n",
    "\n",
    "            # (2) Hindcast High (values and percentages of last 10-year mean)\n",
    "            # - Hindcast\n",
    "            df_hcst = box_hcst_high[fnid].stack().reset_index()\n",
    "            df_hcst = prettytable(df_hcst, fnid, product_name, season_name)\n",
    "            df_hcst['out-of-sample'] = 0\n",
    "            df_hcst['variable'] = 'yield_fcst_high'\n",
    "            # - Forecast\n",
    "            df_fcst = box_fcst_high[fnid].stack().reset_index()\n",
    "            df_fcst = prettytable(df_fcst, fnid, product_name, season_name)\n",
    "            df_fcst['out-of-sample'] = 1\n",
    "            df_fcst['variable'] = 'yield_fcst_high'\n",
    "            # - Reconstruct\n",
    "            df_rcst = box_rcst_high[fnid].stack().reset_index()\n",
    "            df_rcst = prettytable(df_rcst, fnid, product_name, season_name)\n",
    "            df_rcst['out-of-sample'] = 2\n",
    "            df_rcst['variable'] = 'yield_fcst_high'\n",
    "            # - Merge them and remove the hindcast in the forecast period\n",
    "            df = pd.concat([df_rcst, df_hcst, df_fcst], axis=0).reset_index(drop=True)\n",
    "            # df = df.drop_duplicates(df.columns[[0,1,3,4,5,6,7,8,9,11]], keep='last').reset_index(drop=True)\n",
    "            container.append(df.copy())\n",
    "            # - Percentage to long-term mean \n",
    "            df_prct_long = df.copy()\n",
    "            df_prct_long['value'] = df_prct_long['value']/yield_long*100\n",
    "            df_prct_long['variable'] = 'yield_fcst_high_p30'\n",
    "            container.append(df_prct_long)\n",
    "            # - Percentage to last 10-year mean\n",
    "            df_prct_last10 = df.copy()\n",
    "            df_prct_last10['value'] = df_prct_last10['value']/yield_last10*100\n",
    "            df_prct_last10['variable'] = 'yield_fcst_high_p10'\n",
    "            container.append(df_prct_last10)\n",
    "\n",
    "            # (4) Hindcast error\n",
    "            # - Hindcast\n",
    "            df_hcst = box_hcst_error[fnid].stack().reset_index()\n",
    "            df_hcst = prettytable(df_hcst, fnid, product_name, season_name)\n",
    "            df_hcst['out-of-sample'] = 0\n",
    "            df_hcst['variable'] = 'yield_fcst_error'\n",
    "            # - Forecast\n",
    "            df_fcst = box_fcst_error[fnid].stack().reset_index()\n",
    "            df_fcst = prettytable(df_fcst, fnid, product_name, season_name)\n",
    "            df_fcst['out-of-sample'] = 1\n",
    "            df_fcst['variable'] = 'yield_fcst_error'\n",
    "            # - Merge them and remove the hindcast in the forecast period\n",
    "            df = pd.concat([df_hcst, df_fcst], axis=0).reset_index(drop=True)\n",
    "            # df = df.drop_duplicates(df.columns[[0,1,3,4,5,6,7,8,9,11]], keep='last').reset_index(drop=True)\n",
    "            container.append(df.copy())\n",
    "        container = pd.concat(container, axis=0)\n",
    "        container = pd.merge(container, dist_info, left_on='fnid', right_on='fnid')\n",
    "        container_hcst = container[[*column_order, 'lead']]\n",
    "\n",
    "        # NSE Hindcast\n",
    "        temp = box_nse_hcst\n",
    "        temp = temp.stack().reset_index()\n",
    "        temp.columns = ['fnid','lead','value']\n",
    "        temp['variable'] = 'yield_nse'\n",
    "        base = container_hcst[['fnid','country','admin1','admin2','product','season','month','dekad','day','lead']].drop_duplicates()\n",
    "        container_nse_hcst = pd.merge(temp, base, left_on=['fnid','lead'], right_on=['fnid','lead'], how='outer')\n",
    "        container_nse_hcst['out-of-sample'] = 0\n",
    "        # NSE Forecast\n",
    "        temp = box_nse_fcst\n",
    "        temp = temp.stack().reset_index()\n",
    "        temp.columns = ['fnid','lead','value']\n",
    "        temp['variable'] = 'yield_nse'\n",
    "        base = container_hcst[['fnid','country','admin1','admin2','product','season','month','dekad','day','lead']].drop_duplicates()\n",
    "        container_nse_fcst = pd.merge(temp, base, left_on=['fnid','lead'], right_on=['fnid','lead'], how='outer')\n",
    "        container_nse_fcst['out-of-sample'] = 1\n",
    "\n",
    "        # MAPE Hindcast\n",
    "        temp = box_mape_hcst*100\n",
    "        temp = temp.stack().reset_index()\n",
    "        temp.columns = ['fnid','lead','value']\n",
    "        temp['variable'] = 'yield_mape'\n",
    "        base = container_hcst[['fnid','country','admin1','admin2','product','season','month','dekad','day','lead']].drop_duplicates()\n",
    "        container_mape_hcst = pd.merge(temp, base, left_on=['fnid','lead'], right_on=['fnid','lead'], how='outer')\n",
    "        container_mape_hcst['out-of-sample'] = 0\n",
    "        # MAPE Forecast\n",
    "        temp = box_mape_fcst*100\n",
    "        temp = temp.stack().reset_index()\n",
    "        temp.columns = ['fnid','lead','value']\n",
    "        temp['variable'] = 'yield_mape'\n",
    "        base = container_hcst[['fnid','country','admin1','admin2','product','season','month','dekad','day','lead']].drop_duplicates()\n",
    "        container_mape_fcst = pd.merge(temp, base, left_on=['fnid','lead'], right_on=['fnid','lead'], how='outer')\n",
    "        container_mape_fcst['out-of-sample'] = 1\n",
    "\n",
    "        # Merge forecast results and MAPE\n",
    "        container_forecast = pd.concat([\n",
    "            container_hcst, \n",
    "            container_nse_hcst, container_nse_fcst,\n",
    "            container_mape_hcst, container_mape_fcst,\n",
    "        ], axis=0)[column_order].reset_index(drop=True)\n",
    "\n",
    "        # # Exclude districts modeled with insufficient records\n",
    "        # min_records = 15\n",
    "        # sub_info = fnids_info[\n",
    "        #     (fnids_info['country'] == country_name) &\n",
    "        #     (fnids_info['product'] == product_name) &\n",
    "        #     (fnids_info['season_name'] == season_name)\n",
    "        # ]\n",
    "        # fnids_valid = sub_info.loc[sub_info['record'] >= min_records, 'fnid'].values.tolist()\n",
    "        # container_forecast = container_forecast[container_forecast['fnid'].isin(fnids_valid)]\n",
    "        container_forecast['model'] = model_name\n",
    "        container_out.append(container_forecast)\n",
    "    container_forecast = pd.concat(container_out, axis=0).reset_index(drop=True)\n",
    "    # -------------------------------------------------- #\n",
    "    \n",
    "    \n",
    "    # Season start month and Forecast start month ------ #\n",
    "    # Start months of crop season and forecast\n",
    "    cols = ['country','product','season','forecast_start_month','season_start_month']\n",
    "    start = [\n",
    "        ['Somalia','Sorghum','Gu',2,3],\n",
    "        ['Somalia','Sorghum','Deyr',9,10],\n",
    "        ['Somalia','Maize','Gu',2,3],\n",
    "        ['Somalia','Maize','Deyr',9,10],\n",
    "        ['Malawi','Maize','Main',10,11],\n",
    "        ['Kenya','Maize','Long',2,3],\n",
    "        ['Kenya','Maize','Short',9,10],\n",
    "        ['Burkina Faso','Maize','Main',4,5],\n",
    "    ]\n",
    "    start = pd.DataFrame(start, columns=cols)\n",
    "    # -------------------------------------------------- #\n",
    "    \n",
    "    \n",
    "    # Save the \"viewer_com.csv\" ------------------------ #\n",
    "    # Export data\n",
    "    # container = pd.concat([container_crop, container_forecast], axis=0).reset_index(drop=True)\n",
    "    container = pd.concat([container_forecast], axis=0).reset_index(drop=True)\n",
    "    container = container.merge(start, on=['country','product','season'], how='outer') # 'outer' for 'crop_area_percent'\n",
    "    container = container[['fnid','country','admin1','admin2','year','product','season',\n",
    "                           'forecast_start_month','season_start_month',\n",
    "                           'month','dekad','day','model','out-of-sample','variable','value']]\n",
    "    container = container[container['variable'].notna()]\n",
    "    fn_out = './viewer/viewer_data_com.csv'\n",
    "    container.to_csv(fn_out)\n",
    "    print('%s is saved.' % fn_out)\n",
    "\n",
    "    # # Export shapefile\n",
    "    # fn_out = './viewer/viewer_data.shp'\n",
    "    # shape.to_file(fn_out)\n",
    "    # print('%s is saved.' % fn_out)\n",
    "    \n",
    "    df = pd.read_csv('./viewer/viewer_data_com.csv', low_memory=False).drop(['Unnamed: 0'],axis=1)\n",
    "    df['date'] = pd.to_datetime(df[['year','month','day']])\n",
    "    cps = df.loc[df['season'].notna(),['country','product','season']].drop_duplicates().reset_index(drop=True)\n",
    "    for i, (country_name, product_name, season_name) in cps.iterrows():\n",
    "        sub = df[\n",
    "            (df['country'] == country_name) &\n",
    "            (df['product'] == product_name) &\n",
    "            (df['season'] == season_name) &\n",
    "            (df['year'].isin([2022,2023])) &\n",
    "            (df['out-of-sample'] == 2) &\n",
    "            (df['variable'] == 'yield_fcst')\n",
    "        ]\n",
    "        # print(sub.groupby(['country','fnid','product','season'])['date'].max())\n",
    "        cps.loc[i,'latest'] = sub['date'].max()\n",
    "    print(cps)\n",
    "    # print(df['variable'].unique())\n",
    "    # df[['out-of-sample','variable']].drop_duplicates()\n",
    "    # -------------------------------------------------- #\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b54cb5-68c7-4bad-9f5e-e70bcb1fb77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somalia-Sorghum-Deyr-ET\n",
      "Somalia-Sorghum-Gu-ET\n",
      "Somalia-Maize-Deyr-ET\n",
      "Somalia-Maize-Gu-ET\n",
      "Malawi-Maize-Main-ET\n",
      "Kenya-Maize-Long-ET\n",
      "Kenya-Maize-Short-ET\n",
      "Burkina Faso-Maize-Main-ET\n"
     ]
    }
   ],
   "source": [
    "generate_viewer_com()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986c09d6-a0d0-4447-b41d-38130e2e1914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
